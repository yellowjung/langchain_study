{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.218559Z",
     "start_time": "2025-11-03T07:07:02.185241Z"
    }
   },
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import ssl\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function = embedding_function,\n",
    "    collection_name = 'income_tax_collection',\n",
    "    persist_directory = './income_tax_collection'\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.223402Z",
     "start_time": "2025-11-03T07:07:02.221787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ],
   "id": "e1a83ece98cf6a27",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.227303Z",
     "start_time": "2025-11-03T07:07:02.225809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    return {'context': docs}  # 검색된 문서를 포함한 state를 반환합니다."
   ],
   "id": "759f102110a81378",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.230831Z",
     "start_time": "2025-11-03T07:07:02.229334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ],
   "id": "73154eb6bbb01131",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.425505Z",
     "start_time": "2025-11-03T07:07:02.232750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "generate_llm = ChatOpenAI(model='gpt-4o', max_completion_tokens=100)\n",
    "def generate(state: AgentState):\n",
    "    context = state['context']\n",
    "    query = state['query']\n",
    "    rag_chain = generate_prompt | generate_llm\n",
    "    response = rag_chain.invoke({'question': query, 'context': context})\n",
    "    return {'answer': response.content}"
   ],
   "id": "bbc31bd86d589989",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.430318Z",
     "start_time": "2025-11-03T07:07:02.428467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "dictionary = ['사람과 관련된 표현 -> 거주자']\n",
    "\n",
    "rewrite_prompt = PromptTemplate.from_template(f\"\"\"\n",
    "사용자의 질문을 보고, 우리의 사전을 참고해서 사용자의 질문을 변경해주세요\n",
    "사전: {dictionary}\n",
    "질문: {{query}}\n",
    "\"\"\")\n",
    "\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "\n",
    "    Args:\n",
    "         state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 변경된 질문을 포함하는 stat를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state['query']\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "    response = rewrite_chain.invoke({'query': query})\n",
    "    return {'query': response}"
   ],
   "id": "a6703cec438c5a7a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.625169Z",
     "start_time": "2025-11-03T07:07:02.432224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from typing import Literal\n",
    "\n",
    "# 문서 관련성 판단을 위한 프롬프트를 가져옵니다.\n",
    "doc_relevance_prompt = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "def check_doc_relevance(state: AgentState) -> Literal['relevant', 'irrelevant']:\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    context = state['context']  # state에서 문맥을 추출합니다.\n",
    "    print(f'context: {context}')\n",
    "    doc_relevance_chain = doc_relevance_prompt | llm\n",
    "\n",
    "    response = doc_relevance_chain.invoke({'question': query, 'documents': context})\n",
    "    print(f'doc relevance: {response}')\n",
    "    if response['Score'] == 1:\n",
    "        return 'relevant'\n",
    "\n",
    "    return 'irrelevant'"
   ],
   "id": "70a94267b840210d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.629689Z",
     "start_time": "2025-11-03T07:07:02.627686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "hallucination_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a teacher tasked with evaluating whether a student's answer is based on documents or not,\n",
    "Given documents, which are excerpts from income tax law, and a student's answer;\n",
    "If the student's answer is based on documents, response with \"not hallucinated\"\n",
    "If the student's answer is not based on documents, response with \"hallucinated\"\n",
    "\n",
    "documents: {documents}\n",
    "student_answer = {student_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "hallucination_llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "def check_hallucination(state: AgentState) -> Literal['hallucinated', 'not hallucinated']:\n",
    "    answer = state['answer']\n",
    "    context = state['context']\n",
    "    context = [doc.page_content for doc in context]\n",
    "    hallucination_chain = hallucination_prompt | hallucination_llm\n",
    "    response = hallucination_chain.invoke({'student_answer': answer, 'documents': context})\n",
    "    print(f'hallucination response: {response}')\n",
    "    return response.content\n"
   ],
   "id": "e21adf8185d70e77",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.828465Z",
     "start_time": "2025-11-03T07:07:02.632799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "helpfulness_prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def check_helpfulness(state: AgentState):\n",
    "    query = state['query']\n",
    "    answer = state['answer']\n",
    "    helpfulness_chain = helpfulness_prompt | llm\n",
    "    response = helpfulness_chain.invoke({'question': query, 'student_answer': answer})\n",
    "    print(f'helpfulness response: {response}')\n",
    "    if response['Score'] == 1:\n",
    "        return 'helpful'\n",
    "    return 'unhelpful'"
   ],
   "id": "bb27bceb0e67742e",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:07:02.838504Z",
     "start_time": "2025-11-03T07:07:02.835086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph_builder.add_node('retrieve', retriever)\n",
    "graph_builder.add_node('generate', generate)\n",
    "graph_builder.add_node('check_doc_relevance', check_doc_relevance)\n",
    "graph_builder.add_node('check_hallucination', check_hallucination)\n",
    "graph_builder.add_node('check_helpfulness', check_helpfulness)\n",
    "graph_builder.add_node('rewrite', rewrite)"
   ],
   "id": "7c9f0b096c48ab8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10e53e190>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64e3dec533f1d5ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
